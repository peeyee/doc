0.安装前准备
参考文档 http://hadoop.apache.org/docs/r1.0.4/cn/cluster_setup.html
0.1 关闭防火墙
service iptables statu2.SSH配置免密
0.2 关闭Selinux
很多稀奇古怪的问题都是SELINUX导致的。


1. 创建用户
useradd hadoop -d /home/hadoop
echo hadoop|passwd hadoop --stdin
生成密钥文件 
ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
将公钥拷贝至各节点,并导入至公钥文件中。[ssh-copy-id hadoop1]
scp id_rsa.pub xxx@ip:~/.ssh/file
cat id_rsa.pub >> authorized_keys
配置SSHD的配置，启用如下两项
RSAAuthentication yes
PubkeyAuthentication yess


如果发现ssh hostnamexx还是提示输入密码的话，需查看/var/log/secure中的日志信息，查询具体的错误，通常是目录权限不对，
一般要把密码文件的权限设为600，chmod 600 .ssh/xxx

3.修改配置文件

3.1 core-site.xml

<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://hmaster/:9000</value>
<final>true</final>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>file:/home/hadoop/tmp</value>
</property>
<property>
<name>io.file.buffer.size</name>
<value>131072</value>
</property>
</configuration>


3.2 hdfs-site.xml

<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.data.dir</name>
<value>/home/hadoop/hdfs/data</value>
</property>
<property>
<property>
<name>dfs.name.dir</name>
<value>/home/hadoop/hdfs/name</value>
</property>
<property>
<name>dfs.webhdfs.enabled</name>
<value>true</value>
</property>
</configuration>


3.3 mapred-site.xml

<configuration>
<property>
<name>mapred.job.tracker</name>
<value>hmaster:8021</value>
</property>
<property>
<name>mapred.local.dir</name>
<value>/tmp/hadoop/mapred/local</value>
</property>
<property>
<name>mapred.system.dir</name>
<value>/tmp/hadoop/mapred/system</value>
</property>
<property>
<name>mapred.tasktracker.map.tasks.maximum</name>
<value>2</value>
</property>
<property>
<name>mapred.tasktracker.reduce.tasks.maximum</name>
<value>2</value>
</property>
<property>
<name>mapred.child.java.opts</name>
<value>Xmx200m</value>
</property>
<property>
<name>mapred.jobhistory.address</name>
<value>hmaster:10020</value>
</property>
<property>
<name>mapred.jobhistory.webapp.address</name>
<value>hmaster:19888</value>
</property>
</configuration>

3.4 yarn-site.xml
<configuration>
<!-- Site specific YARN configuration properties -->
<property>
<name>yarn.resourcemanager.address</name>
<value>hmaster:8032</value>
</property>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>mapreduce.shuffle</value>
</property>
<property>
<name>yarn.nodemanager.webapp.address</name>
<value>hmaster:8088</value>
</property>
</configuration>

注意
master节点 /etc/hosts的前两行一定要注释掉
#127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4 oracle-11g
#::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
不然会在127.0.0.1上起namenode的服务，而导致相关访问服务拒绝。

3.5 设置环境变量


PATH=$PATH:$HOME/bin:$HOME/sbin:$HADOOP_HOME/sbin:$HADOOP_HOME/bin
JAVA_HOME=/usr/local/src/jdk1.8
export HADOOP_HOME=/home/hadoop/hadoop
export JAVA_HOME=/usr/local/src/jdk1.8
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export LD_LIBRARY_PATH=$HADOOP_HOME/lib/native

3.6 配置slaves文件
每一个行 写上slave的IP，如
[hadoop@hadoop1 hadoop]$ cat slaves
192.168.43.199


4. 初始化
4.1 格式化HDFS文件系统
hadoop namenode -format
看到 Exiting with status 0就说明成功初始化了。
在master，slave用JPS查看进程
有namenode，secondary namenode，datanode就正常了。


5.web系统
master:50070 是namenode的web地址
master:19888 jobhistory的web地址 