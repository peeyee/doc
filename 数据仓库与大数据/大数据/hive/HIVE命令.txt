--hive 不区分大小写
--表，列建议都小写

/*Hive从0.14版本开始支持事务和行级更新,但缺省是不支持的,需要一些附加的配置。
要想支持行级insert、update、delete,需要配置Hive支持事务。*/


1.数据库操作
create database test;
show databases;
use test;
describe database test;
drop database if exists test cascade;--慎重使用

2.表级操作
show tables;

--2.1 复制表结构
create table if not exists test.student2 like test.student; 

--2.2 创建表

/*--
\001 - ctrl + A ,列分隔符
\002 - ctrl + B ,结构体的分隔符
\003 - ctrl + C ,键值对的分割符

--*/
create table if not exists student (
name string comment 'name',
age int comment 'age',
cource array<string> comment 'courses',
body map<string,float>,
address struct<street:string, city:string, state:string>)
row format delimited fields terminated by '\001'
collection items terminated by '\002'
map keys terminated by '\003'
lines terminated by '\n'
stored as textfile; --|sequencefile|rcfile textfile简单，但是不支持压缩
				   /*sequencefile 按行分割，支持压缩，是hadoop原生的二进制格式*/
				   /*rcfile 按列存储，一行数据不跨块*/
创建完表之后，在hdfs上会有一个以此表名为目录的文件夹。


--2.2.1 外部表
如果数据是由其他软件所共有的，这份数据的所有权不由hive拥有，不由HIVE来管理，可以建外部表的方式。
create external table if not exists student2(
name string comment 'name',
age int,
courses array<string>,
body map<string,float> comment 'sanwei',
address struct<street:string,city:string,state:string>

)
location '/tmp/test' -- 文件所在的目录 |local location '/tmp/test'，指定local关键字可以从本地文件系统读取文件。



--2.3 查看表
show tables; show tables in databasexxx;
desc student;



--2.4 修改表

--2.4.1 重命名表
alter table student rename to student3;

--2.4.2 修改列
alter table student change column name name2 string
comment 'name2';

--2.4.3 增加列
alter table student add columns (add1 string comment 'test add',add2 int comment 'test add');

--2.4.4 删除列
--待验证


--分区表

分区是hive一个重要的特性，hive没有索引,通过分区扫描从而避免全表扫描。
分区在hdfs上是对应的文件夹形式来存在数据文件。

create table student_prt(
studentid int,
name string,
age int,
sex string
)
partitioned by (province string, city string);
其中分区字段出现在patition子句中，不得在定义表的字段中出现。

在hdfs上会出现如下目录
hdfs:/user/hive/warehouse/student_info/zhejiang/hangzhou
hdfs:/user/hive/warehouse/student_info/zhejiang/huzhou
...

/*严格模式*/
可以将查询模式设置为strict，从而限制HQL一定要加上分区条件。

--session级别的
set hive.mapred.mode=strict;


外部表也可以有分区
LOAD DATA [local] INPATH '/user/hadoop/data' into student_info partition (province='1', city='2'); 

--修改配置文件,全局级别
hive.mapred.mode=>strict


3. 数据操作
3.1 导入数据
3.1.1插入数据
load data [local] inpath '/tmp/test2' into table student; -- 追加模式
load data [local] inpath '/tmp/test2' overwrite into table student; -- 覆盖模式
加上关键字local可以从本地文件读取而非hdfs。

3.1.2
insert overwrite table student select * from student2;



3.1.3
create table student2 as select * from student;

3.1.4
动态分区
根据查询的结果创建分区
insert overwrite table student partition(age) select id,age from student;
hive会根据分区的数量将最后N个字段作为分区的依据。

开启动态分区,会话级别
set hive.exec.dynamic.partition = true;


3.2 导出数据

insert overwrite directory '/tmp/test' select * from student;
insert overwrite local directory '/tmp/test' select * from student;




3.3 数据查询
--3.3.1
select name
from student
where 1=1
group by name
having 1=1
order by name|sort by name  -- 结果全局有序
 -- 单个reduce输出有序
 
 case when 语法
 case 
	 when id=1 then ''
	 when id=2 then ''
	 else ''
 end
select name,age from student distribute by name sort by name,age
 --distribute by 控制map的输出如何分发给reduce
distribute by col1 sort by col1 == cluster by col1


--3.3.2 关联

--== student -- student_info

inner join 内连接 两者条件相等的
left|right|full  out join 外连接
left semi join 左半连接，效率比较快，对应左边一条记录，只要在右边找到一条符合关联条件的就停止扫描右表。
	select a.id,a.name from student a inner join 
	student_info b on a.id = b.id 
	
	select a.name  from student3 a left semi join student_info b on a.id = b.id ;-- 选取了已选课的学生
	
union all

hive 使用union all 必须使用嵌套查询

select r.id,r.name from
(select a.id,a.name from student3 a 
union all
select b.id,b.name from student3 b )r;


3.4 分桶与抽样

select id,name from student3 tablesample(bucket 1 out of 3 on id);
按id列进行hash分桶，取1/3的桶数据。
也可以随机抽取rand()
select id,name from student3 tablesample(bucket 1 out of 3 on rand());

通过分桶抽样可以有效地提高分析开发数据程序的效率。


3.5  自定义函数UDF
编写udf要继承 org.apache.hadoop.hive.ql.exec.UDF,并继承evaluate函数


